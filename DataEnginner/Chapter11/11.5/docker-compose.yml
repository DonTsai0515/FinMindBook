version: '3.0'
services:
  crawler_twse:
    build:
      context: .
      dockerfile: Dockerfile.cache
    image: linsamtw/crawler:11.5
    hostname: "twse"
    command: pipenv run celery -A financialdata.tasks.worker worker --loglevel=info --concurrency=1  --hostname=%h -Q twse
    restart: always
    # swarm 設定
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.labels.crawler_twse == true]
    environment:
      - TZ=Asia/Taipei
    networks:
        - my_network

  crawler_tpex:
    build:
      context: .
      dockerfile: Dockerfile.cache
    image: linsamtw/crawler:11.5
    hostname: "twse"
    command: pipenv run celery -A financialdata.tasks.worker worker --loglevel=info --concurrency=1  --hostname=%h -Q tpex
    restart: always
    # swarm 設定
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.labels.crawler_tpex == true]
    environment:
      - TZ=Asia/Taipei
    networks:
        - my_network

  scheduler:
    build:
      context: .
      dockerfile: Dockerfile.cache
    image: linsamtw/crawler:11.5
    hostname: "twse"
    command: pipenv run python financialdata/scheduler.py
    restart: always
    environment:
      - TZ=Asia/Taipei
    networks:
        - my_network

networks:
  my_network:
    # 加入已經存在的網路
    external: true
